# -*- coding: utf-8 -*-
"""Feature_Extraction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1csZabjaVL9m6MWXaRL0ZoOsR3x6SbcVY
"""

from google.colab import drive
drive.mount('/content/drive')

! pip install -q mne pyriemann

import os, glob, json, re
from pathlib import Path
import numpy as np
import pandas as pd
from tqdm import tqdm
import mne
from mne.time_frequency import psd_array_welch
from pyriemann.estimation import Covariances
from pyriemann.tangentspace import TangentSpace

DATASET_ROOT = "/content/drive/MyDrive/1:1_Bhavya_Kottapalli/Data/ds004796-download" #data folder for eeg
SUBJECTS_CSV = "/content/drive/MyDrive/1:1_Bhavya_Kottapalli/Processed_Data/subjects.csv" #output file from previous code blocks
FEATURES_DIR = "/content/drive/MyDrive/1:1_Bhavya_Kottapalli/Processed_Data/Featurized_Data" #folder for features output of code saved

# variables constants
TMIN =  -0.2
TMAX = 0.8
HPF = 1.0
LPF = 40.0
NOTCH = 60.0
REJECT_PTP_UV = 150.0  # reject if any channel p2p > 150 µV
BANDS =  { "theta": (4,8), "alpha": (8,12), "beta": (13,30) }
MIN_EPOCHS = 20

def pick_eeg(raw):
    picks = mne.pick_types(raw.info, eeg=True, eog=False, meg=False, stim=False, exclude="bads")
    return picks

def load_events_tsv(tsv_path):
    ev = pd.read_csv(tsv_path, sep="\t")
    # Use 'onset' column (seconds from start). Treat every row as an event.
    onsets = ev["onset"].values.astype(float)
    # Duration may be 0; we’ll epoch fixed window around onset
    desc = ev["trial_type"].astype(str).values if "trial_type" in ev.columns else np.array(["event"]*len(onsets))
    return onsets, desc

def epoch_file(sub, task):
  eeg_dir = os.path.join(DATASET_ROOT, f"sub-{sub}", "eeg")
  # Accept files with run-*, etc.
  vhdrs = sorted(glob.glob(os.path.join(eeg_dir, f"sub-{sub}_task-{task}*_eeg.vhdr")))
  evts_all = sorted(glob.glob(os.path.join(eeg_dir, f"sub-{sub}_task-{task}*_events.tsv")))
  if len(vhdrs) == 0 or len(evts_all) == 0:
        return None
  X_list = []
  sfreq_ref = None
  for vhdr in vhdrs:
    # Try to find an events.tsv matching the same run; else fall back to the first
    m = re.search(r"run-(\d+)", os.path.basename(vhdr))
    if m:
            run = m.group(1)
            evts = [e for e in evts_all if f"run-{run}" in os.path.basename(e)]
            evts = evts[0:1] or evts_all[0:1]
    else:
            evts = evts_all[0:1]
    try:
            raw = mne.io.read_raw_brainvision(vhdr, preload=True, verbose=False)
    except Exception as e:
            print(f"[WARN] Cannot read {vhdr}: {e}")
            continue
    # Basic clean
    drop = [ch for ch in raw.ch_names if ch.upper().startswith(("ECG","EMG","EOG"))]
    if drop: raw.drop_channels(drop)
    #filtering out wanted frequencies above and below the specified frequencies
    raw.filter(HPF, LPF, fir_design="firwin", verbose=False)
    try:
            if NOTCH is not None:
                raw.notch_filter(NOTCH, verbose=False)
    except Exception:
            pass

    # Average ref fallback; if mastoids exist you could prefer them
    raw.set_eeg_reference("average", projection=False, verbose=False)
    picks = mne.pick_types(raw.info, eeg=True, eog=False, meg=False, stim=False, exclude="bads")
    sfreq = raw.info["sfreq"]
    sfreq_ref = sfreq if sfreq_ref is None else sfreq_ref
    # Load events
    onsets, desc = load_events_tsv(evts[0])
    if len(onsets) == 0:
      continue
    #calculating the sample indice
    sample_onsets = (onsets * sfreq).astype(int)
    events = np.column_stack([sample_onsets, np.zeros_like(sample_onsets), np.ones_like(sample_onsets, dtype=int)])
    epochs = mne.Epochs(raw, events, event_id={"event":1},
                            tmin=TMIN, tmax=TMAX,
                            baseline=(TMIN, 0.0),
                            picks=picks, preload=True, detrend=1, verbose=False)
    # Simple artifact rejection
    data = epochs.get_data()
    ptp = (data.max(axis=2) - data.min(axis=2))  # (n_epochs, n_ch)
    good = (ptp < REJECT_PTP_UV * 1e-6).all(axis=1)
    data = data[good]
    if len(data) == 0:
      continue
    X_list.append(data)
  if len(X_list)==0:
    return None
  X = np.concatenate(X_list, axis=0)


  # Riemannian covariance -> tangent space
  cov = Covariances(estimator="oas").fit_transform(X)
  ts = TangentSpace().fit(cov)
  X_ts = ts.transform(cov)

  # Bandpower (mean across channels)
  bp_feats = []
  for name, (fmin, fmax) in BANDS.items():
        psd, freqs = psd_array_welch(X, sfreq=sfreq_ref, fmin=fmin, fmax=fmax,
                                     n_fft=int(sfreq_ref*0.5), average='mean')
        bandpow = psd.sum(axis=2).mean(axis=1, keepdims=True)
        bp_feats.append(bandpow)
  X_bp = np.concatenate(bp_feats, axis=1)
  #adding 2 numpy arrays
  X_feat = np.concatenate([X_ts, X_bp], axis=1)
  #checking if there is less than 20 epoches and if so it will not be used
  if X_feat.shape[0] < MIN_EPOCHS:
        return None
  #Dictionary of feuatures (info about feautures)
  info = {
        "n_epochs": int(X_feat.shape[0]),
        "n_channels": int(X.shape[1]),
        "tangent_dim": int(X_ts.shape[1]),
        "bp_dim": int(X_bp.shape[1]),
        "sfreq": float(sfreq_ref),
        "tmin": TMIN, "tmax": TMAX,
        "bandpass": [HPF, LPF],
        "n_runs": len(vhdrs),
    }
  return X_feat, info

def save_npz(task, sub, X, y, task_id, subj_id, out_dir):
    os.makedirs(os.path.join(out_dir, task), exist_ok=True)
    out = os.path.join(out_dir, task, f"sub-{sub}.npz")
    np.savez_compressed(out, X=X.astype(np.float32), y=y.astype(np.int64),
                        task_id=np.full(len(y), task_id, dtype=np.int64),
                        subj_id=np.full(len(y), subj_id, dtype=np.int64))
    return out

# read the subject csv
subs = pd.read_csv(SUBJECTS_CSV)
subs = subs[subs["usable_both_tasks"]==True].copy()
print(f"Subjects with both tasks: {len(subs)}")

for _, row in tqdm(subs.iterrows(), total=len(subs)):
    ## Try some if statements to skip already run subjects, so that only new subjects will be run

    sub = str(row["subject"])
    label = int(row["label"])  # subject-level label
    for task, tid in [("msit",0),("sternberg",1)]:
        res = epoch_file(sub, task)
        if res is None:
            print(f"[WARN] Skipping sub-{sub} task-{task} (not enough/any epochs).")
            continue
        X, info = res
        y = np.full(X.shape[0], label, dtype=int)
        outp = save_npz(task, sub, X, y, task_id=tid, subj_id=int(sub),
                        out_dir=FEATURES_DIR)
        print(f"Saved {outp} | {info}")